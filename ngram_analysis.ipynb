{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ngram_analysis.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEClJlB4FmFj",
        "colab_type": "text"
      },
      "source": [
        "Import data from https://github.com/EdinburghNLP/code-docstring-corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aToTCs00FmFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.util import everygrams\n",
        "import nltk\n",
        "from nltk.tokenize.simple import CharTokenizer\n",
        "from collections import Counter\n",
        "import itertools\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsi3fjCIIOeX",
        "colab_type": "text"
      },
      "source": [
        "# Compute n-grams from English and Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e2PElInFmF7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "716ef578-beb5-416d-9853-3c821d60f221"
      },
      "source": [
        "# dl Reuters english corpus\n",
        "nltk.download(\"reuters\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLkxrh7wFmGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "4649e947-ecc4-4338-c695-c228be08a21d"
      },
      "source": [
        "char_stream = CharTokenizer().tokenize(\" \".join(nltk.corpus.reuters.words()).lower())\n",
        "print(\"number English characters in corpus: \", len(char_stream))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number English characters in corpus:  8607412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC3SFzEEFmG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "2ea9ceb4-394f-4c97-b8ce-6d95be59c575"
      },
      "source": [
        "# everygram_counts = Counter(everygrams(char_stream, max_len=15))  # out of RAM lol time to chunk\n",
        "\n",
        "\n",
        "bigass_iterator = everygrams(char_stream, max_len=15)\n",
        "\n",
        "#https://stackoverflow.com/a/8998040/4212158\n",
        "def grouper_it(n, iterable):  # split iterable into iterable of iterables\n",
        "    it = iter(iterable)\n",
        "    while True:\n",
        "        chunk_it = itertools.islice(it, n)\n",
        "        try:\n",
        "            first_el = next(chunk_it)\n",
        "        except StopIteration:\n",
        "            return\n",
        "        yield itertools.chain((first_el,), chunk_it)\n",
        "\n",
        "everygram_counts = Counter()\n",
        "for ngrams in grouper_it(100000, bigass_iterator):  # process everygrams in chunks of 100k\n",
        "  chunk_ngram_counts = Counter(ngrams)\n",
        "  for gram in chunk_ngram_counts.copy():\n",
        "      # remove small instance words\n",
        "      if chunk_ngram_counts[gram] <= 3:\n",
        "        del chunk_ngram_counts[gram]\n",
        "  everygram_counts += chunk_ngram_counts  # add to big list"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1aaee0029f5246529de83f0e36aa2659",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=100000000000000000000), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UTOXQxaFmHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4104
        },
        "outputId": "4bd10799-1b8c-4df3-9ae3-eeb379fb6d36"
      },
      "source": [
        "print(\"total of {} everygrams\".format(len(everygram_counts)))\n",
        "top_tuples = everygram_counts.most_common(200)\n",
        "for tup in top_tuples:\n",
        "    # convert ('a', 'n', 'd' to 'and')\n",
        "    print(\"<\" + \"\".join([x for x in tup[0]]) + \"> \" + str(tup[1]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total of 511807 everygrams\n",
            "< > 1720900\n",
            "<e> 716143\n",
            "<t> 561269\n",
            "<a> 522478\n",
            "<s> 477753\n",
            "<n> 465177\n",
            "<i> 459254\n",
            "<o> 457385\n",
            "<r> 453146\n",
            "<l> 291178\n",
            "<d> 267469\n",
            "<c> 235795\n",
            "<s > 218828\n",
            "<h> 218447\n",
            "<e > 199450\n",
            "<u> 172119\n",
            "< t> 167140\n",
            "<m> 165732\n",
            "<p> 160060\n",
            "<f> 142348\n",
            "<t > 141721\n",
            "<d > 139616\n",
            "<n > 134288\n",
            "< a> 130812\n",
            "< s> 128985\n",
            "<in> 124556\n",
            "<th> 116850\n",
            "<g> 112522\n",
            "<.> 99809\n",
            "<an> 98296\n",
            "<he> 98212\n",
            "<er> 98002\n",
            "< .> 97586\n",
            "<b> 96512\n",
            "<re> 96248\n",
            "<. > 95677\n",
            "< . > 94687\n",
            "< th> 93645\n",
            "<y> 93552\n",
            "< i> 92402\n",
            "<r > 87786\n",
            "<on> 84402\n",
            "< o> 82179\n",
            "< c> 82028\n",
            "<w> 81967\n",
            "<the> 81192\n",
            "<,> 77632\n",
            "< the> 75874\n",
            "< ,> 75766\n",
            "<he > 74832\n",
            "<, > 74173\n",
            "<v> 73038\n",
            "< , > 72360\n",
            "<es> 71773\n",
            "<ar> 70609\n",
            "<the > 69292\n",
            "< the > 69277\n",
            "< p> 67974\n",
            "<y > 67526\n",
            "<or> 64230\n",
            "< b> 63988\n",
            "< m> 63343\n",
            "<0> 62811\n",
            "<te> 62229\n",
            "<to> 59864\n",
            "<st> 59821\n",
            "< f> 59135\n",
            "<en> 57852\n",
            "<at> 56710\n",
            "<ed> 56517\n",
            "<it> 56262\n",
            "< in> 55307\n",
            "<o > 55129\n",
            "<co> 54090\n",
            "<ti> 52952\n",
            "<al> 52538\n",
            "< d> 52370\n",
            "<nd> 52218\n",
            "< w> 51804\n",
            "<1> 51589\n",
            "<l > 50151\n",
            "<nt> 50060\n",
            "<ed > 49020\n",
            "<of> 47862\n",
            "< to> 46376\n",
            "< r> 45850\n",
            "<ro> 44960\n",
            "<ng> 43592\n",
            "<k> 43481\n",
            "< of> 42921\n",
            "<de> 42637\n",
            "<ne> 42524\n",
            "<f > 42423\n",
            "<ai> 42130\n",
            "<se> 41402\n",
            "<on > 41155\n",
            "< 1> 41106\n",
            "< co> 40773\n",
            "<es > 40318\n",
            "<ha> 40264\n",
            "< l> 40097\n",
            "<er > 39272\n",
            "<as> 39217\n",
            "<io> 39092\n",
            "<ct> 38539\n",
            "<a > 38157\n",
            "<to > 37973\n",
            "<sa> 37695\n",
            "<g > 37423\n",
            "<id> 37260\n",
            "<ra> 37243\n",
            "<is> 36978\n",
            "<of > 36811\n",
            "< of > 36779\n",
            "< to > 36400\n",
            "< e> 36206\n",
            "<ou> 35701\n",
            "< an> 35689\n",
            "<ts> 35612\n",
            "<ri> 35477\n",
            "<ea> 35460\n",
            "<in > 35072\n",
            "<ve> 35020\n",
            "<ing> 35019\n",
            "<nd > 34913\n",
            "<me> 34508\n",
            "<ts > 34328\n",
            "<ion> 34211\n",
            "<pr> 33787\n",
            "< sa> 33763\n",
            "<om> 33634\n",
            "<il> 33189\n",
            "<ng > 33147\n",
            "< n> 33115\n",
            "<rs> 32603\n",
            "<ll> 32539\n",
            "< h> 32449\n",
            "<0 > 31994\n",
            "<ic> 31117\n",
            "<ing > 30814\n",
            "<and> 30798\n",
            "< re> 30506\n",
            "<2> 29541\n",
            "<li> 29356\n",
            "< in > 29253\n",
            "<ec> 29243\n",
            "<le> 29231\n",
            "<ma> 29065\n",
            "<ce> 28666\n",
            "<et> 28662\n",
            "<ta> 28396\n",
            "<and > 28349\n",
            "<8> 28055\n",
            "<id > 27910\n",
            "<h > 27682\n",
            "<rs > 27526\n",
            "< pr> 27424\n",
            "<tr> 26965\n",
            "<5> 26455\n",
            "<aid> 26096\n",
            "<aid > 25925\n",
            "<ur> 25795\n",
            "<sai> 25754\n",
            "< and> 25734\n",
            "<ent> 25683\n",
            "< and > 25648\n",
            "<9> 25459\n",
            "< sai> 25438\n",
            "<said> 25386\n",
            "< said> 25385\n",
            "<said > 25384\n",
            "< said > 25383\n",
            "<00> 25152\n",
            "< a > 25103\n",
            "<nc> 25066\n",
            "<3> 25065\n",
            "<ion > 24280\n",
            "<fo> 23605\n",
            "<di> 23605\n",
            "<pe> 23479\n",
            "<tio> 23256\n",
            "<la> 23235\n",
            "<tion> 23080\n",
            "<ch> 23076\n",
            "<rt> 22936\n",
            "<pa> 22932\n",
            "<sh> 22643\n",
            "<or > 22308\n",
            "<al > 22245\n",
            "<d t> 22230\n",
            "<si> 22169\n",
            "<be> 22098\n",
            "<6> 21869\n",
            "<s a> 21823\n",
            "<an > 21782\n",
            "< g> 21780\n",
            "<fi> 21684\n",
            "<el> 21463\n",
            "<4> 21149\n",
            "<lo> 20929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdx_jB7gXiRY",
        "colab_type": "text"
      },
      "source": [
        "# superset of chars\n",
        "\n",
        "does not include any captial letters tho"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gg82wszXlL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "outputId": "d1b2cc23-0731-492f-ef4f-85e8e1bf3f0b"
      },
      "source": [
        "\n",
        "# print(string.printable)\n",
        "# print(len(string.printable))\n",
        "\n",
        "everygram_superset = set()\n",
        "top_tuples = everygram_counts.most_common(5000)\n",
        "for tup in top_tuples:\n",
        "  for char in tup[0]:\n",
        "    everygram_superset.add(char)\n",
        "  \n",
        "#print(sorted(everygram_superset))\n",
        "\n",
        "missing = set(string.printable) - everygram_superset\n",
        "print(sorted(missing))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\t', '\\n', '\\x0b', '\\x0c', '\\r', '!', '#', '$', '%', '*', '+', '<', '=', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR_x9TsXFmHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}