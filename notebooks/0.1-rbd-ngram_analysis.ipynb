{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ngram_analysis.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "auDWbvTCu0m1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "7bcb5cc7-0fcb-4184-adcc-e1ce4a9031e7"
      },
      "source": [
        "!pip install google-ngram-downloader"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google-ngram-downloader\n",
            "  Downloading https://files.pythonhosted.org/packages/6e/18/06f89c493fbdf753163322e19a1680f67139526a7da7fd0cd506d5591ac5/google-ngram-downloader-4.0.1.tar.gz\n",
            "Collecting opster (from google-ngram-downloader)\n",
            "  Downloading https://files.pythonhosted.org/packages/ce/57/c527704b78ab2763c32ac3e6d7b1940c069bfeebcfafe7b948a80f30bcff/opster-4.2.tar.gz\n",
            "Requirement already satisfied: py in /usr/local/lib/python3.6/dist-packages (from google-ngram-downloader) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from google-ngram-downloader) (2.21.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->google-ngram-downloader) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->google-ngram-downloader) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->google-ngram-downloader) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->google-ngram-downloader) (3.0.4)\n",
            "Building wheels for collected packages: google-ngram-downloader, opster\n",
            "  Building wheel for google-ngram-downloader (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/2f/58/b276b0d5c6aa83128500ff40af60142ffdc73d649e3892ccd2\n",
            "  Building wheel for opster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/c9/9a/249e1a1b257e4de5851902455374637c4d68af63e933803569\n",
            "Successfully built google-ngram-downloader opster\n",
            "Installing collected packages: opster, google-ngram-downloader\n",
            "Successfully installed google-ngram-downloader-4.0.1 opster-4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEClJlB4FmFj",
        "colab_type": "text"
      },
      "source": [
        "Import data from https://github.com/EdinburghNLP/code-docstring-corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aToTCs00FmFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.util import everygrams\n",
        "import nltk\n",
        "from nltk.tokenize.simple import CharTokenizer\n",
        "from collections import Counter\n",
        "import itertools\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vyQp6jvu6rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google_ngram_downloader import readline_google_store\n",
        "\n",
        "goog_ngram_counts = Counter()\n",
        "\n",
        "\n",
        "ngram_generators = []\n",
        "# for each n\n",
        "for n in range(1,5):\n",
        "    upstream_ngram_generators_generator = readline_google_store(ngram_len=n)\n",
        "    for generator in upstream_ngram_generators_generator:\n",
        "        fname, url, records = generator\n",
        "        ngram_generators.append(records)\n",
        "print(ngram_generators)\n",
        "\n",
        "for gen in ngram_generators:\n",
        "    for record in gen:\n",
        "        print(record)\n",
        "\n",
        "# i = 0\n",
        "# while i < 20000:\n",
        "#     record = next(records)\n",
        "#     #print(record)\n",
        "#     # skip ngrams with tags in them\n",
        "#     # see https://books.google.com/ngrams/info\n",
        "#     if record.match_count < 6000 or \"_\" in record.ngram:\n",
        "#         continue\n",
        "#     else:\n",
        "#         i += 1\n",
        "#         if i > 5000:\n",
        "#             print(\"key \", record.ngram)\n",
        "#             print(\"count \", record.match_count)\n",
        "           \n",
        "\n",
        "# print(fname)\n",
        "# print(url)\n",
        "# print(next(records))\n",
        "# print(next(records))\n",
        "# record"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsi3fjCIIOeX",
        "colab_type": "text"
      },
      "source": [
        "# Compute n-grams from English and Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e2PElInFmF7",
        "colab_type": "code",
        "outputId": "e3e05369-c008-4556-9196-d792c8bfcc15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        }
      },
      "source": [
        "# dl Reuters english corpus\n",
        "nltk.download(\"reuters\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLkxrh7wFmGN",
        "colab_type": "code",
        "outputId": "44a84101-ecd0-4473-b1c0-84cce79d8c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "char_stream = CharTokenizer().tokenize(\" \".join(nltk.corpus.reuters.words()).lower())\n",
        "print(\"number English characters in corpus: \", len(char_stream))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number English characters in corpus:  8607412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC3SFzEEFmG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# everygram_counts = Counter(everygrams(char_stream, max_len=15))  # out of RAM lol time to chunk\n",
        "\n",
        "\n",
        "bigass_iterator = everygrams(char_stream, max_len=15)\n",
        "\n",
        "#https://stackoverflow.com/a/8998040/4212158\n",
        "def grouper_it(n, iterable):  # split iterable into iterable of iterables\n",
        "    it = iter(iterable)\n",
        "    while True:\n",
        "        chunk_it = itertools.islice(it, n)\n",
        "        try:\n",
        "            first_el = next(chunk_it)\n",
        "        except StopIteration:\n",
        "            return\n",
        "        yield itertools.chain((first_el,), chunk_it)\n",
        "\n",
        "everygram_counts = Counter()\n",
        "for ngrams in grouper_it(100000, bigass_iterator):  # process everygrams in chunks of 100k\n",
        "  chunk_ngram_counts = Counter(ngrams)\n",
        "  for gram in chunk_ngram_counts.copy():\n",
        "      # remove small instance words\n",
        "      if chunk_ngram_counts[gram] <= 3:\n",
        "        del chunk_ngram_counts[gram]\n",
        "  everygram_counts += chunk_ngram_counts  # add to big list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UTOXQxaFmHN",
        "colab_type": "code",
        "outputId": "8e117289-3519-4180-a087-292e27c0f03a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4104
        }
      },
      "source": [
        "print(\"total of {} everygrams\".format(len(everygram_counts)))\n",
        "top_tuples = everygram_counts.most_common(200)\n",
        "for tup in top_tuples:\n",
        "    # convert ('a', 'n', 'd' to 'and')\n",
        "    print(\"<\" + \"\".join([x for x in tup[0]]) + \"> \" + str(tup[1]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total of 511807 everygrams\n",
            "< > 1720900\n",
            "<e> 716143\n",
            "<t> 561269\n",
            "<a> 522478\n",
            "<s> 477753\n",
            "<n> 465177\n",
            "<i> 459254\n",
            "<o> 457385\n",
            "<r> 453146\n",
            "<l> 291178\n",
            "<d> 267469\n",
            "<c> 235795\n",
            "<s > 218828\n",
            "<h> 218447\n",
            "<e > 199450\n",
            "<u> 172119\n",
            "< t> 167140\n",
            "<m> 165732\n",
            "<p> 160060\n",
            "<f> 142348\n",
            "<t > 141721\n",
            "<d > 139616\n",
            "<n > 134288\n",
            "< a> 130812\n",
            "< s> 128985\n",
            "<in> 124556\n",
            "<th> 116850\n",
            "<g> 112522\n",
            "<.> 99809\n",
            "<an> 98296\n",
            "<he> 98212\n",
            "<er> 98002\n",
            "< .> 97586\n",
            "<b> 96512\n",
            "<re> 96248\n",
            "<. > 95677\n",
            "< . > 94687\n",
            "< th> 93645\n",
            "<y> 93552\n",
            "< i> 92402\n",
            "<r > 87786\n",
            "<on> 84402\n",
            "< o> 82179\n",
            "< c> 82028\n",
            "<w> 81967\n",
            "<the> 81192\n",
            "<,> 77632\n",
            "< the> 75874\n",
            "< ,> 75766\n",
            "<he > 74832\n",
            "<, > 74173\n",
            "<v> 73038\n",
            "< , > 72360\n",
            "<es> 71773\n",
            "<ar> 70609\n",
            "<the > 69292\n",
            "< the > 69277\n",
            "< p> 67974\n",
            "<y > 67526\n",
            "<or> 64230\n",
            "< b> 63988\n",
            "< m> 63343\n",
            "<0> 62811\n",
            "<te> 62229\n",
            "<to> 59864\n",
            "<st> 59821\n",
            "< f> 59135\n",
            "<en> 57852\n",
            "<at> 56710\n",
            "<ed> 56517\n",
            "<it> 56262\n",
            "< in> 55307\n",
            "<o > 55129\n",
            "<co> 54090\n",
            "<ti> 52952\n",
            "<al> 52538\n",
            "< d> 52370\n",
            "<nd> 52218\n",
            "< w> 51804\n",
            "<1> 51589\n",
            "<l > 50151\n",
            "<nt> 50060\n",
            "<ed > 49020\n",
            "<of> 47862\n",
            "< to> 46376\n",
            "< r> 45850\n",
            "<ro> 44960\n",
            "<ng> 43592\n",
            "<k> 43481\n",
            "< of> 42921\n",
            "<de> 42637\n",
            "<ne> 42524\n",
            "<f > 42423\n",
            "<ai> 42130\n",
            "<se> 41402\n",
            "<on > 41155\n",
            "< 1> 41106\n",
            "< co> 40773\n",
            "<es > 40318\n",
            "<ha> 40264\n",
            "< l> 40097\n",
            "<er > 39272\n",
            "<as> 39217\n",
            "<io> 39092\n",
            "<ct> 38539\n",
            "<a > 38157\n",
            "<to > 37973\n",
            "<sa> 37695\n",
            "<g > 37423\n",
            "<id> 37260\n",
            "<ra> 37243\n",
            "<is> 36978\n",
            "<of > 36811\n",
            "< of > 36779\n",
            "< to > 36400\n",
            "< e> 36206\n",
            "<ou> 35701\n",
            "< an> 35689\n",
            "<ts> 35612\n",
            "<ri> 35477\n",
            "<ea> 35460\n",
            "<in > 35072\n",
            "<ve> 35020\n",
            "<ing> 35019\n",
            "<nd > 34913\n",
            "<me> 34508\n",
            "<ts > 34328\n",
            "<ion> 34211\n",
            "<pr> 33787\n",
            "< sa> 33763\n",
            "<om> 33634\n",
            "<il> 33189\n",
            "<ng > 33147\n",
            "< n> 33115\n",
            "<rs> 32603\n",
            "<ll> 32539\n",
            "< h> 32449\n",
            "<0 > 31994\n",
            "<ic> 31117\n",
            "<ing > 30814\n",
            "<and> 30798\n",
            "< re> 30506\n",
            "<2> 29541\n",
            "<li> 29356\n",
            "< in > 29253\n",
            "<ec> 29243\n",
            "<le> 29231\n",
            "<ma> 29065\n",
            "<ce> 28666\n",
            "<et> 28662\n",
            "<ta> 28396\n",
            "<and > 28349\n",
            "<8> 28055\n",
            "<id > 27910\n",
            "<h > 27682\n",
            "<rs > 27526\n",
            "< pr> 27424\n",
            "<tr> 26965\n",
            "<5> 26455\n",
            "<aid> 26096\n",
            "<aid > 25925\n",
            "<ur> 25795\n",
            "<sai> 25754\n",
            "< and> 25734\n",
            "<ent> 25683\n",
            "< and > 25648\n",
            "<9> 25459\n",
            "< sai> 25438\n",
            "<said> 25386\n",
            "< said> 25385\n",
            "<said > 25384\n",
            "< said > 25383\n",
            "<00> 25152\n",
            "< a > 25103\n",
            "<nc> 25066\n",
            "<3> 25065\n",
            "<ion > 24280\n",
            "<fo> 23605\n",
            "<di> 23605\n",
            "<pe> 23479\n",
            "<tio> 23256\n",
            "<la> 23235\n",
            "<tion> 23080\n",
            "<ch> 23076\n",
            "<rt> 22936\n",
            "<pa> 22932\n",
            "<sh> 22643\n",
            "<or > 22308\n",
            "<al > 22245\n",
            "<d t> 22230\n",
            "<si> 22169\n",
            "<be> 22098\n",
            "<6> 21869\n",
            "<s a> 21823\n",
            "<an > 21782\n",
            "< g> 21780\n",
            "<fi> 21684\n",
            "<el> 21463\n",
            "<4> 21149\n",
            "<lo> 20929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdx_jB7gXiRY",
        "colab_type": "text"
      },
      "source": [
        "# superset of chars\n",
        "\n",
        "does not include any captial letters tho"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gg82wszXlL9",
        "colab_type": "code",
        "outputId": "d1b2cc23-0731-492f-ef4f-85e8e1bf3f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        }
      },
      "source": [
        "\n",
        "# print(string.printable)\n",
        "# print(len(string.printable))\n",
        "\n",
        "everygram_superset = set()\n",
        "top_tuples = everygram_counts.most_common(5000)\n",
        "for tup in top_tuples:\n",
        "  for char in tup[0]:\n",
        "    everygram_superset.add(char)\n",
        "  \n",
        "#print(sorted(everygram_superset))\n",
        "\n",
        "missing = set(string.printable) - everygram_superset\n",
        "print(sorted(missing))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\t', '\\n', '\\x0b', '\\x0c', '\\r', '!', '#', '$', '%', '*', '+', '<', '=', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR_x9TsXFmHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}